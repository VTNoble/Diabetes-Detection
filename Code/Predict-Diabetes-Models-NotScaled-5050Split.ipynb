{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de244296",
   "metadata": {},
   "source": [
    "## Looking at how the models perform on a dataset trimmed to have a 50/50 split on the target variable (Diabetes_binary). Full dataset was over 85% non-diabetic, which can add unwanted bias to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbac5ac",
   "metadata": {},
   "source": [
    "## Part 1: Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e9a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1500dad",
   "metadata": {},
   "source": [
    "Load the data into a Pandas DataFrame and fetch the top 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef2f01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1              0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2              0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3              0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4              0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "5              0.0     0.0       0.0        1.0  18.0     0.0     0.0   \n",
       "6              0.0     0.0       1.0        1.0  26.0     1.0     0.0   \n",
       "7              0.0     0.0       0.0        1.0  31.0     1.0     0.0   \n",
       "8              0.0     0.0       0.0        1.0  32.0     0.0     0.0   \n",
       "9              0.0     0.0       0.0        1.0  27.0     1.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           1.0     0.0  ...            1.0   \n",
       "1                   0.0           0.0     1.0  ...            1.0   \n",
       "2                   0.0           1.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "5                   0.0           1.0     1.0  ...            0.0   \n",
       "6                   0.0           1.0     1.0  ...            1.0   \n",
       "7                   0.0           0.0     1.0  ...            1.0   \n",
       "8                   0.0           1.0     1.0  ...            1.0   \n",
       "9                   0.0           0.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      3.0       5.0      30.0       0.0  1.0   4.0        6.0   \n",
       "1          0.0      3.0       0.0       0.0       0.0  1.0  12.0        6.0   \n",
       "2          0.0      1.0       0.0      10.0       0.0  1.0  13.0        6.0   \n",
       "3          0.0      3.0       0.0       3.0       0.0  1.0  11.0        6.0   \n",
       "4          0.0      2.0       0.0       0.0       0.0  0.0   8.0        5.0   \n",
       "5          0.0      2.0       7.0       0.0       0.0  0.0   1.0        4.0   \n",
       "6          0.0      1.0       0.0       0.0       0.0  1.0  13.0        5.0   \n",
       "7          0.0      4.0       0.0       0.0       0.0  1.0   6.0        4.0   \n",
       "8          0.0      3.0       0.0       0.0       0.0  0.0   3.0        6.0   \n",
       "9          0.0      3.0       0.0       6.0       0.0  1.0   6.0        4.0   \n",
       "\n",
       "   Income  \n",
       "0     8.0  \n",
       "1     8.0  \n",
       "2     8.0  \n",
       "3     8.0  \n",
       "4     8.0  \n",
       "5     7.0  \n",
       "6     6.0  \n",
       "7     3.0  \n",
       "8     8.0  \n",
       "9     4.0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in CSV\n",
    "file_path = Path(\"../Resources/diabetes_data_5050split.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ecc07",
   "metadata": {},
   "source": [
    "List the DataFrame's data types to ensure they're aligned to the type of data stored on each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6b5c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary         float64\n",
       "HighBP                  float64\n",
       "HighChol                float64\n",
       "CholCheck               float64\n",
       "BMI                     float64\n",
       "Smoker                  float64\n",
       "Stroke                  float64\n",
       "HeartDiseaseorAttack    float64\n",
       "PhysActivity            float64\n",
       "Fruits                  float64\n",
       "Veggies                 float64\n",
       "HvyAlcoholConsump       float64\n",
       "AnyHealthcare           float64\n",
       "NoDocbcCost             float64\n",
       "GenHlth                 float64\n",
       "MentHlth                float64\n",
       "PhysHlth                float64\n",
       "DiffWalk                float64\n",
       "Sex                     float64\n",
       "Age                     float64\n",
       "Education               float64\n",
       "Income                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List dataframe data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a8698f",
   "metadata": {},
   "source": [
    "Remove all rows with `null` values if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee934b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Diabetes_binary has 0 null values\n",
      "Column HighBP has 0 null values\n",
      "Column HighChol has 0 null values\n",
      "Column CholCheck has 0 null values\n",
      "Column BMI has 0 null values\n",
      "Column Smoker has 0 null values\n",
      "Column Stroke has 0 null values\n",
      "Column HeartDiseaseorAttack has 0 null values\n",
      "Column PhysActivity has 0 null values\n",
      "Column Fruits has 0 null values\n",
      "Column Veggies has 0 null values\n",
      "Column HvyAlcoholConsump has 0 null values\n",
      "Column AnyHealthcare has 0 null values\n",
      "Column NoDocbcCost has 0 null values\n",
      "Column GenHlth has 0 null values\n",
      "Column MentHlth has 0 null values\n",
      "Column PhysHlth has 0 null values\n",
      "Column DiffWalk has 0 null values\n",
      "Column Sex has 0 null values\n",
      "Column Age has 0 null values\n",
      "Column Education has 0 null values\n",
      "Column Income has 0 null values\n"
     ]
    }
   ],
   "source": [
    "# Find null values\n",
    "for column in df.columns:\n",
    "    print(f\"Column {column} has {df[column].isnull().sum()} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c2b101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Diabetes_binary has 0.0 as minimum value\n",
      "Column Diabetes_binary has 1.0 as maximum value\n",
      "Column HighBP has 0.0 as minimum value\n",
      "Column HighBP has 1.0 as maximum value\n",
      "Column HighChol has 0.0 as minimum value\n",
      "Column HighChol has 1.0 as maximum value\n",
      "Column CholCheck has 0.0 as minimum value\n",
      "Column CholCheck has 1.0 as maximum value\n",
      "Column BMI has 12.0 as minimum value\n",
      "Column BMI has 98.0 as maximum value\n",
      "Column Smoker has 0.0 as minimum value\n",
      "Column Smoker has 1.0 as maximum value\n",
      "Column Stroke has 0.0 as minimum value\n",
      "Column Stroke has 1.0 as maximum value\n",
      "Column HeartDiseaseorAttack has 0.0 as minimum value\n",
      "Column HeartDiseaseorAttack has 1.0 as maximum value\n",
      "Column PhysActivity has 0.0 as minimum value\n",
      "Column PhysActivity has 1.0 as maximum value\n",
      "Column Fruits has 0.0 as minimum value\n",
      "Column Fruits has 1.0 as maximum value\n",
      "Column Veggies has 0.0 as minimum value\n",
      "Column Veggies has 1.0 as maximum value\n",
      "Column HvyAlcoholConsump has 0.0 as minimum value\n",
      "Column HvyAlcoholConsump has 1.0 as maximum value\n",
      "Column AnyHealthcare has 0.0 as minimum value\n",
      "Column AnyHealthcare has 1.0 as maximum value\n",
      "Column NoDocbcCost has 0.0 as minimum value\n",
      "Column NoDocbcCost has 1.0 as maximum value\n",
      "Column GenHlth has 1.0 as minimum value\n",
      "Column GenHlth has 5.0 as maximum value\n",
      "Column MentHlth has 0.0 as minimum value\n",
      "Column MentHlth has 30.0 as maximum value\n",
      "Column PhysHlth has 0.0 as minimum value\n",
      "Column PhysHlth has 30.0 as maximum value\n",
      "Column DiffWalk has 0.0 as minimum value\n",
      "Column DiffWalk has 1.0 as maximum value\n",
      "Column Sex has 0.0 as minimum value\n",
      "Column Sex has 1.0 as maximum value\n",
      "Column Age has 1.0 as minimum value\n",
      "Column Age has 13.0 as maximum value\n",
      "Column Education has 1.0 as minimum value\n",
      "Column Education has 6.0 as maximum value\n",
      "Column Income has 1.0 as minimum value\n",
      "Column Income has 8.0 as maximum value\n"
     ]
    }
   ],
   "source": [
    "# Look at min and max values\n",
    "for column in df.columns:\n",
    "    print(f\"Column {column} has {df[column].min()} as minimum value\")\n",
    "    print(f\"Column {column} has {df[column].max()} as maximum value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4124449d",
   "metadata": {},
   "source": [
    "No null values were found. Check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984e0e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 1635\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate entries\n",
    "print(f\"Duplicate entries: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c52052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate entries\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be74e85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 0\n"
     ]
    }
   ],
   "source": [
    "# Confirm that duplicate entries have been dropped\n",
    "print(f\"Duplicate entries: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba1382e",
   "metadata": {},
   "source": [
    "Check for duplicates but ignore the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "781c5686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries excluding the target variable: 408\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate entries ignoring target column\n",
    "features = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
    "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
    "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
    "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
    "       'Income']\n",
    "print(f\"Duplicate entries excluding the target variable: {df.duplicated(subset=features).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d4d45be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate entries\n",
    "df = df.drop_duplicates(subset=features, keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "024ecb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries excluding the target variable: 0\n"
     ]
    }
   ],
   "source": [
    "# Confirm that duplicate entries have been dropped\n",
    "print(f\"Duplicate entries excluding the target variable: {df.duplicated(subset=features).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "728e6833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68241, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate shape after dropping duplicates\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65440499",
   "metadata": {},
   "source": [
    "Export CSV for Tableau Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1bee3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csv. commented out to avoid overwriting file once exported\n",
    "#df.to_csv('../Resources/viz_data.csv', index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33f910b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function by Boern found in the following link \n",
    "# https://stackoverflow.com/questions/31323499/sklearn-error-valueerror-input-contains-nan-infinity-or-a-value-too-large-for\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd956822",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = clean_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a946eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature (X) and target (y) variables\n",
    "X = df_cleaned.drop('Diabetes_binary', axis=1)\n",
    "y = df_cleaned['Diabetes_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6210d5",
   "metadata": {},
   "source": [
    "Look at X and y to make sure everything looks as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90ed5c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0     1.0       0.0        1.0  26.0     0.0     0.0                   0.0   \n",
       "1     1.0       1.0        1.0  26.0     1.0     1.0                   0.0   \n",
       "2     0.0       0.0        1.0  26.0     0.0     0.0                   0.0   \n",
       "3     1.0       1.0        1.0  28.0     1.0     0.0                   0.0   \n",
       "4     0.0       0.0        1.0  29.0     1.0     0.0                   0.0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
       "0           1.0     0.0      1.0  ...            1.0          0.0      3.0   \n",
       "1           0.0     1.0      0.0  ...            1.0          0.0      3.0   \n",
       "2           1.0     1.0      1.0  ...            1.0          0.0      1.0   \n",
       "3           1.0     1.0      1.0  ...            1.0          0.0      3.0   \n",
       "4           1.0     1.0      1.0  ...            1.0          0.0      2.0   \n",
       "\n",
       "   MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \n",
       "0       5.0      30.0       0.0  1.0   4.0        6.0     8.0  \n",
       "1       0.0       0.0       0.0  1.0  12.0        6.0     8.0  \n",
       "2       0.0      10.0       0.0  1.0  13.0        6.0     8.0  \n",
       "3       0.0       3.0       0.0  1.0  11.0        6.0     8.0  \n",
       "4       0.0       0.0       0.0  0.0   8.0        5.0     8.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview X\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95d5495a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: Diabetes_binary, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prevew y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf6725ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de4c4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tester(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f'Training Score: {clf.score(X_train, y_train)}')\n",
    "    print(f'Testing Score: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d98e71a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonnoble/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.72      0.74      8342\n",
      "         1.0       0.74      0.78      0.76      8719\n",
      "\n",
      "    accuracy                           0.75     17061\n",
      "   macro avg       0.75      0.75      0.75     17061\n",
      "weighted avg       0.75      0.75      0.75     17061\n",
      "\n",
      "Training Score: 0.7386479093395858\n",
      "Testing Score: 0.7475528984233046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.72      0.74      8342\n",
      "         1.0       0.75      0.78      0.76      8719\n",
      "\n",
      "    accuracy                           0.75     17061\n",
      "   macro avg       0.75      0.75      0.75     17061\n",
      "weighted avg       0.75      0.75      0.75     17061\n",
      "\n",
      "Training Score: 0.7449980461117625\n",
      "Testing Score: 0.7541761913135221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.72      0.74      8342\n",
      "         1.0       0.75      0.78      0.76      8719\n",
      "\n",
      "    accuracy                           0.75     17061\n",
      "   macro avg       0.75      0.75      0.75     17061\n",
      "weighted avg       0.75      0.75      0.75     17061\n",
      "\n",
      "Training Score: 0.7449980461117625\n",
      "Testing Score: 0.7541761913135221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.72      0.74      8342\n",
      "         1.0       0.75      0.78      0.76      8719\n",
      "\n",
      "    accuracy                           0.75     17061\n",
      "   macro avg       0.75      0.75      0.75     17061\n",
      "weighted avg       0.75      0.75      0.75     17061\n",
      "\n",
      "Training Score: 0.7449980461117625\n",
      "Testing Score: 0.7541761913135221\n"
     ]
    }
   ],
   "source": [
    "# Look at different Logistic Regression models and find bester performing for further tuning\n",
    "model_tester(LogisticRegression(random_state=42), X, y)\n",
    "model_tester(LogisticRegression(random_state=42, max_iter=500), X, y)\n",
    "model_tester(LogisticRegression(random_state=42, max_iter=1000), X, y)\n",
    "model_tester(LogisticRegression(random_state=42, max_iter=10000), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f22bc72",
   "metadata": {},
   "source": [
    "The second model with max_iter=500 is the model selected as the 'best' LogisticRegression model. The accuracy scores leveled off for 1000 and 10000 suggesting there were diminishing returns for the additional iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b28cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.70      0.73      8342\n",
      "         1.0       0.73      0.79      0.76      8719\n",
      "\n",
      "    accuracy                           0.74     17061\n",
      "   macro avg       0.75      0.74      0.74     17061\n",
      "weighted avg       0.74      0.74      0.74     17061\n",
      "\n",
      "Training Score: 0.9999804611176241\n",
      "Testing Score: 0.743801652892562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.69      0.72      8342\n",
      "         1.0       0.72      0.77      0.75      8719\n",
      "\n",
      "    accuracy                           0.73     17061\n",
      "   macro avg       0.73      0.73      0.73     17061\n",
      "weighted avg       0.73      0.73      0.73     17061\n",
      "\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.7337201805286911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.69      0.73      8342\n",
      "         1.0       0.73      0.79      0.76      8719\n",
      "\n",
      "    accuracy                           0.75     17061\n",
      "   macro avg       0.75      0.74      0.74     17061\n",
      "weighted avg       0.75      0.75      0.75     17061\n",
      "\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.7459703417150225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.69      0.72      8342\n",
      "         1.0       0.73      0.78      0.75      8719\n",
      "\n",
      "    accuracy                           0.74     17061\n",
      "   macro avg       0.74      0.74      0.74     17061\n",
      "weighted avg       0.74      0.74      0.74     17061\n",
      "\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.7368266807338374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.69      0.73      8342\n",
      "         1.0       0.73      0.80      0.76      8719\n",
      "\n",
      "    accuracy                           0.75     17061\n",
      "   macro avg       0.75      0.74      0.74     17061\n",
      "weighted avg       0.75      0.75      0.74     17061\n",
      "\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.7453255963894262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.69      0.72      8342\n",
      "         1.0       0.72      0.78      0.75      8719\n",
      "\n",
      "    accuracy                           0.74     17061\n",
      "   macro avg       0.74      0.74      0.74     17061\n",
      "weighted avg       0.74      0.74      0.74     17061\n",
      "\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.7366508410995839\n"
     ]
    }
   ],
   "source": [
    "# Look at different RandomForest models and find bester performing for further tuning\n",
    "model_tester(RandomForestClassifier(random_state=42), X, y)\n",
    "model_tester(RandomForestClassifier(random_state=42, bootstrap=False), X, y)\n",
    "model_tester(RandomForestClassifier(random_state=42, n_estimators=200), X, y)\n",
    "model_tester(RandomForestClassifier(random_state=42, n_estimators=200, bootstrap=False), X, y)\n",
    "model_tester(RandomForestClassifier(random_state=42, n_estimators=500), X, y)\n",
    "model_tester(RandomForestClassifier(random_state=42, n_estimators=500, bootstrap=False), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71489750",
   "metadata": {},
   "source": [
    "The third model with n_estimators=200 and the default bootstrap setting is selected as the 'best' Random Forest model. This is due to it having the highest testing accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a7f7ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.75      8342\n",
      "         1.0       0.75      0.79      0.77      8719\n",
      "\n",
      "    accuracy                           0.76     17061\n",
      "   macro avg       0.76      0.76      0.76     17061\n",
      "weighted avg       0.76      0.76      0.76     17061\n",
      "\n",
      "Training Score: 0.7465806955842126\n",
      "Testing Score: 0.758630795381279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.75      8342\n",
      "         1.0       0.75      0.79      0.77      8719\n",
      "\n",
      "    accuracy                           0.76     17061\n",
      "   macro avg       0.76      0.76      0.76     17061\n",
      "weighted avg       0.76      0.76      0.76     17061\n",
      "\n",
      "Training Score: 0.7467956232903478\n",
      "Testing Score: 0.758220502901354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.75      8342\n",
      "         1.0       0.75      0.79      0.77      8719\n",
      "\n",
      "    accuracy                           0.76     17061\n",
      "   macro avg       0.76      0.76      0.76     17061\n",
      "weighted avg       0.76      0.76      0.76     17061\n",
      "\n",
      "Training Score: 0.7453497459945291\n",
      "Testing Score: 0.7593341539182932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.75      8342\n",
      "         1.0       0.75      0.79      0.77      8719\n",
      "\n",
      "    accuracy                           0.76     17061\n",
      "   macro avg       0.76      0.76      0.76     17061\n",
      "weighted avg       0.76      0.76      0.76     17061\n",
      "\n",
      "Training Score: 0.7466979288784682\n",
      "Testing Score: 0.7583377293241896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.74      8342\n",
      "         1.0       0.75      0.79      0.77      8719\n",
      "\n",
      "    accuracy                           0.76     17061\n",
      "   macro avg       0.76      0.76      0.76     17061\n",
      "weighted avg       0.76      0.76      0.76     17061\n",
      "\n",
      "Training Score: 0.7468737788198515\n",
      "Testing Score: 0.7579274368442647\n"
     ]
    }
   ],
   "source": [
    "# Look at different AdaBoost models and find bester performing for further tuning\n",
    "model_tester(AdaBoostClassifier(random_state=42, n_estimators=100), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=42, n_estimators=200), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=42, n_estimators=200, learning_rate=0.1), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=42, n_estimators=500, learning_rate=0.1), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=42, n_estimators=1000, learning_rate=0.1), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b54054",
   "metadata": {},
   "source": [
    "The model with n_estimators=200 and learnign rate = 0.1 is performing the best. Next, we will try to further tune by changing the learning_rate and keeping the n_estimators the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a785158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.75      8342\n",
      "         1.0       0.75      0.79      0.77      8719\n",
      "\n",
      "    accuracy                           0.76     17061\n",
      "   macro avg       0.76      0.76      0.76     17061\n",
      "weighted avg       0.76      0.76      0.76     17061\n",
      "\n",
      "Training Score: 0.7467956232903478\n",
      "Testing Score: 0.758220502901354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.75      8342\n",
      "         1.0       0.75      0.79      0.77      8719\n",
      "\n",
      "    accuracy                           0.76     17061\n",
      "   macro avg       0.76      0.76      0.76     17061\n",
      "weighted avg       0.76      0.76      0.76     17061\n",
      "\n",
      "Training Score: 0.7453497459945291\n",
      "Testing Score: 0.7593341539182932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.74      8342\n",
      "         1.0       0.75      0.79      0.77      8719\n",
      "\n",
      "    accuracy                           0.76     17061\n",
      "   macro avg       0.76      0.76      0.76     17061\n",
      "weighted avg       0.76      0.76      0.76     17061\n",
      "\n",
      "Training Score: 0.7437280187573271\n",
      "Testing Score: 0.7565207197702362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.72      0.73      8342\n",
      "         1.0       0.74      0.76      0.75      8719\n",
      "\n",
      "    accuracy                           0.74     17061\n",
      "   macro avg       0.74      0.74      0.74     17061\n",
      "weighted avg       0.74      0.74      0.74     17061\n",
      "\n",
      "Training Score: 0.7269245799140289\n",
      "Testing Score: 0.7405779262645801\n"
     ]
    }
   ],
   "source": [
    "# further tune based on results of previous cell\n",
    "model_tester(AdaBoostClassifier(random_state=42, n_estimators=200), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=42, n_estimators=200, learning_rate=0.1), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=42, n_estimators=200, learning_rate=0.05), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=42, n_estimators=200, learning_rate=0.01), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd76b34e",
   "metadata": {},
   "source": [
    "The model with n_estimators=200 and default learning_rate=0.1 is selected as the 'best' Ada Boost model. This is due to it having the highest testing accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3eb755a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.72      0.74      8342\n",
      "         1.0       0.75      0.78      0.76      8719\n",
      "\n",
      "    accuracy                           0.75     17061\n",
      "   macro avg       0.75      0.75      0.75     17061\n",
      "weighted avg       0.75      0.75      0.75     17061\n",
      "\n",
      "Training Score: 0.7449980461117625\n",
      "Testing Score: 0.7541761913135221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.69      0.73      8342\n",
      "         1.0       0.73      0.79      0.76      8719\n",
      "\n",
      "    accuracy                           0.75     17061\n",
      "   macro avg       0.75      0.74      0.74     17061\n",
      "weighted avg       0.75      0.75      0.75     17061\n",
      "\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.7459703417150225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.75      8342\n",
      "         1.0       0.75      0.79      0.77      8719\n",
      "\n",
      "    accuracy                           0.76     17061\n",
      "   macro avg       0.76      0.76      0.76     17061\n",
      "weighted avg       0.76      0.76      0.76     17061\n",
      "\n",
      "Training Score: 0.7453497459945291\n",
      "Testing Score: 0.7593341539182932\n"
     ]
    }
   ],
   "source": [
    "# The best of each type of model\n",
    "model_tester(LogisticRegression(random_state=42, max_iter=500), X, y)\n",
    "model_tester(RandomForestClassifier(random_state=42, n_estimators=200), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=42, n_estimators=200, learning_rate=0.1), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633cbe8",
   "metadata": {},
   "source": [
    "The best performing model of all models tested is the Ada Boost Classifier. With a testing accuracy score of 0.75933 it edged out the Logistic Regression (0.75418) and the Random Forest Classifier (0.74597). It also had the best recall with 0.72.\n",
    "\n",
    "The models with unscaled data performed worse than the models with scaled data on the 50/50 split dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7b30a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
